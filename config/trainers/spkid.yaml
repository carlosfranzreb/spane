trainer:
  max_epochs: 5
  batch_size: 2
  gradient_clip_val: 1.0
  log_every_n_steps: 1
  num_workers: 0
  limit_train_batches: 2
  limit_val_batches: 0

optim:
  name: adamw
  lr: .0000001
  weight_decay: .0002

  sched:
    name: CosineAnnealing
    warmup_ratio: 0.1
    min_lr: 0.0
