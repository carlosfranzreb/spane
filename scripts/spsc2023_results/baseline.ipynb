{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analysis of the results\n",
        "\n",
        "Here we analyse the EER for the three ASV systems and both attack scenarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define the dirs that will be included in this analysis (x-vectors)\n",
        "privacy_dir = \"../../logs/baseline/privacy\"\n",
        "utility_dir = \"../../logs/baseline/utility\"\n",
        "\n",
        "privacy_components = {\n",
        "    \"ignorant\": \"eval/asv-plda/ignorant/results/eer.txt\",\n",
        "}\n",
        "\n",
        "utility_components = {\n",
        "    \"whisper-small\": 4,\n",
        "    \"whisper-large\": 4,\n",
        "    \"nisqa\": 2,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def get_results(privacy_dir, privacy_components, utility_dir, utility_components):\n",
        "\n",
        "    results = dict()\n",
        "\n",
        "    for component, eval_file in privacy_components.items():\n",
        "\n",
        "        path = os.path.join(privacy_dir, eval_file)\n",
        "\n",
        "        with open(path, \"r\") as f:\n",
        "            next(f)  # skip header\n",
        "\n",
        "            for line in f:\n",
        "                elements = line.split(\" \")\n",
        "                dataset = elements[0]\n",
        "                char_value = elements[-1]\n",
        "\n",
        "                if dataset.endswith(\".txt\"):\n",
        "                    dataset = dataset[:-4]\n",
        "                if dataset not in results:\n",
        "                    results[dataset] = dict()\n",
        "                \n",
        "                results[dataset][component] = float(char_value)\n",
        "\n",
        "    for component, value_key in utility_components.items():\n",
        "\n",
        "        path = os.path.join(utility_dir, \"eval\", component, \"all.txt\")\n",
        "        with open(path, \"r\") as f:\n",
        "            next(f)  # skip header\n",
        "\n",
        "            for line in f:\n",
        "                elements = line.split(\" \")\n",
        "                dataset = elements[0]\n",
        "                char_value = elements[value_key]\n",
        "\n",
        "                if dataset.endswith(\".txt\"):\n",
        "                    dataset = dataset[:-4]\n",
        "        \n",
        "                if dataset not in results:\n",
        "                    results[dataset] = dict()\n",
        "\n",
        "                results[dataset][component] = float(char_value)\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = get_results(privacy_dir, privacy_components, utility_dir, utility_components)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| | ignorant | whisper-small | whisper-large | nisqa | \n",
            "| --- | --- | --- | --- | --- | \n",
            "| cv-test_3utts | 0.02 | 0.18 | 0.13 | 2.96 | \n",
            "| ls-test-clean | 0.01 | 0.06 | 0.07 | 3.88 | \n",
            "| edacc-test | 0.05 | 0.32 | 0.29 | 2.63 | \n",
            "| ravdess | 0.04 | 0.01 | 0.0 | 3.37 | \n"
          ]
        }
      ],
      "source": [
        "# print the results in a markdown table\n",
        "print(\"| |\", end=\" \")  # empty cell in the top left corner\n",
        "# print the dataset names as column headers\n",
        "for dataset in results[list(results.keys())[0]]:\n",
        "    print(dataset, end=\" | \")\n",
        "print()  # new line\n",
        "\n",
        "# add hyphens to separate the header from the table\n",
        "print(\"|\", end=\" \")\n",
        "for i in range(len(results) + 1):\n",
        "    print(\"---\", end=\" | \")\n",
        "print()  # new line\n",
        "\n",
        "# print the averages of each dataset for each ASV config\n",
        "for component in results:\n",
        "    print(\"|\", end=\" \")\n",
        "    print(component, end=\" | \")\n",
        "    for dataset in results[component]:\n",
        "        print(round(results[component][dataset], 2), end=\" | \")\n",
        "    print()  # new line\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| | ignorant | whisper-small | whisper-large | nisqa | \n",
        "| --- | --- | --- | --- | --- | \n",
        "| cv-test_3utts | 0.02 | 0.18 | 0.13 | 2.96 | \n",
        "| ls-test-clean | 0.01 | 0.06 | 0.07 | 3.88 | \n",
        "| edacc-test | 0.05 | 0.32 | 0.29 | 2.63 | \n",
        "| ravdess | 0.04 | 0.01 | 0.0 | 3.37 | "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "0303e71b09c4ef6371fdb6bee0728d2bfa84e4cc09a309a2d2b1e6ca43341d44"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
