{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analysis of the results\n",
        "\n",
        "Here we analyse the EER for the three ASV systems and both attack scenarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from string import Template\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define the dirs that will be included in this analysis (x-vectors)\n",
        "privacy_dirs = [\"../../logs/stargan/asv_xvect_lda200\", \"../../logs/stargan/asv_xvect_lda200_2\", \"../../logs/stargan/asv_xvect_lda200_3\"]\n",
        "utility_dirs = [\"../../logs/stargan/utility\"]\n",
        "\n",
        "privacy_components = {\n",
        "    \"ignorant\": Template(\"eval/asv-plda/ignorant/results/eer_$trait.txt\"),\n",
        "    \"lazy-informed\": Template(\"eval/asv-plda/lazy-informed/results/eer_$trait.txt\"),\n",
        "}\n",
        "\n",
        "# map the utility components to the indices of the files that hold the relevant value, and the number of metrics\n",
        "# the first item of each line is assumed to be the dataset; the second, the characteristic; the third, the number of samples\n",
        "utility_components = {\n",
        "    \"whisper-small\": [5, 3],\n",
        "    \"whisper-large\": [5, 3],\n",
        "    \"ser-audeering-w2v\": [3, 7],\n",
        "    \"nisqa\": [3, 1],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def get_results(trait, privacy_dirs, privacy_components, utility_dirs, utility_components):\n",
        "    \"\"\"\n",
        "    Gather the result across the experiment folders for each instance (called here \"char_key\")\n",
        "    of the given trait. For example, the trait \"accent\" can take the values \"US\", \"UK\", \"IN\", etc.\n",
        "    Their respective values are named \"char_value\" in the code below.\n",
        "    \"\"\"\n",
        "\n",
        "    results, n_samples = dict(), dict()\n",
        "\n",
        "    for log_dir in privacy_dirs:\n",
        "\n",
        "        for component, eval_file_template in privacy_components.items():\n",
        "\n",
        "            eval_file = eval_file_template.substitute(trait=trait)\n",
        "            path = os.path.join(log_dir, eval_file)\n",
        "\n",
        "            with open(path, \"r\") as f:\n",
        "                next(f)  # skip header\n",
        "\n",
        "                for line in f:\n",
        "                    elements = line.split(\" \")\n",
        "                    dataset = elements[0]\n",
        "                    char_value = elements[-1]\n",
        "                    char_key = \" \".join(elements[1: len(elements) - 3])\n",
        "\n",
        "                    if dataset.endswith(\".txt\"):\n",
        "                        dataset = dataset[:-4]\n",
        "\n",
        "                    if dataset not in results:\n",
        "                        results[dataset] = dict()\n",
        "                    if char_key not in results[dataset]:\n",
        "                        results[dataset][char_key] = dict()\n",
        "                    if component not in results[dataset][char_key]:\n",
        "                        results[dataset][char_key][component] = list()\n",
        "                    \n",
        "                    results[dataset][char_key][component].append(\n",
        "                        float(char_value)\n",
        "                    )\n",
        "\n",
        "    for log_dir in utility_dirs:\n",
        "        for component, numbers in utility_components.items():\n",
        "            char_value_idx, n_metrics = numbers\n",
        "            path = os.path.join(log_dir, \"eval\", component, f\"{trait}.txt\")\n",
        "            with open(path, \"r\") as f:\n",
        "                next(f)  # skip header\n",
        "\n",
        "                for line in f:\n",
        "                    elements = line.split(\" \")\n",
        "                    dataset = elements[0]\n",
        "                    char_key = \" \".join(elements[1: len(elements) - n_metrics - 1])\n",
        "                    char_value = elements[char_value_idx + len(char_key.split()) - 1]\n",
        "\n",
        "                    if dataset.endswith(\".txt\"):\n",
        "                        dataset = dataset[:-4]\n",
        "\n",
        "                    if dataset not in n_samples:\n",
        "                        n_samples[dataset] = dict()\n",
        "                    if char_key not in n_samples[dataset]:\n",
        "                        n_samples[dataset][char_key] = int(elements[len(char_key.split(\" \")) + 1])\n",
        "                \n",
        "                    if dataset not in results:\n",
        "                        results[dataset] = dict()\n",
        "                    if char_key not in results[dataset]:\n",
        "                        results[dataset][char_key] = dict()\n",
        "                    if component not in results[dataset][char_key]:\n",
        "                        results[dataset][char_key][component] = list()\n",
        "\n",
        "                    results[dataset][char_key][component].append(\n",
        "                        float(char_value)\n",
        "                    )\n",
        "    \n",
        "    return results, n_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_results_per_dataset(results, n_samples, components, min_samples):\n",
        "    # print the results in a markdown table for each dataset\n",
        "    \n",
        "    filtered_char_values = dict()\n",
        "    for dataset in n_samples:\n",
        "        filtered_char_values[dataset] = list()\n",
        "        for char in n_samples[dataset]:\n",
        "            if n_samples[dataset][char] >= min_samples[dataset]:\n",
        "                filtered_char_values[dataset].append(char)\n",
        "\n",
        "    for dataset in results:\n",
        "        print(f\"#### {dataset}\\n\")\n",
        "\n",
        "        print(\"| |\", end=\" \")  # empty cell in the top left corner\n",
        "        # print the dataset names as column headers\n",
        "        for key in filtered_char_values[dataset]:\n",
        "            print(key, end=\" | \")\n",
        "        print()  # new line\n",
        "\n",
        "        # add hyphens to separate the header from the table\n",
        "        print(\"|\", end=\" \")\n",
        "        for _ in range(len(filtered_char_values[dataset]) + 1):\n",
        "            print(\"---\", end=\" | \")\n",
        "        print()  # new line\n",
        "\n",
        "        # get the averages for each key\n",
        "        key_results = {component: list() for component in components}\n",
        "        for key in filtered_char_values[dataset]:\n",
        "            for component in components:\n",
        "                if component not in results[dataset][key]:\n",
        "                    key_results[component].append(\" - \")\n",
        "                else:\n",
        "                    values = results[dataset][key][component]\n",
        "                    key_results[component].append(np.round(np.mean(values), 2))\n",
        "\n",
        "        for component in key_results:\n",
        "            row = [component] + [str(x) for x in key_results[component]]\n",
        "            print(\"| \" + \" | \".join(row) + \" |\")\n",
        "        print()  # new line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#### cv-test_3utts\n",
            "\n",
            "| | nan | United States English | \n",
            "| --- | --- | --- | \n",
            "| ignorant | 0.28 | 0.29 |\n",
            "| lazy-informed | 0.22 | 0.25 |\n",
            "| whisper-small | 0.71 | 0.58 |\n",
            "| whisper-large | 0.53 | 0.43 |\n",
            "| ser-audeering-w2v | 0.99 | 0.99 |\n",
            "| nisqa | 3.41 | 3.59 |\n",
            "\n",
            "#### edacc-test\n",
            "\n",
            "| | Afrian | Nigerian | African accent | Kenyan | Indian  | \n",
            "| --- | --- | --- | --- | --- | --- | \n",
            "| ignorant |  -  | 0.17 |  -  |  -  |  -  |\n",
            "| lazy-informed |  -  | 0.5 |  -  |  -  |  -  |\n",
            "| whisper-small | 0.83 | 0.71 | 1.26 | 0.94 | 17.13 |\n",
            "| whisper-large | 0.64 | 0.6 | 0.96 | 0.71 | 17.13 |\n",
            "| ser-audeering-w2v | 0.99 | 0.99 | 0.99 | 0.99 | 264.0 |\n",
            "| nisqa | 2.56 | 2.82 | 3.23 | 3.06 | 264.0 |\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trait = \"accent\"\n",
        "results, n_samples = get_results(trait, privacy_dirs, privacy_components, utility_dirs, utility_components)\n",
        "components = list(privacy_components) + list(utility_components)\n",
        "print_results_per_dataset(results, n_samples, components, min_samples={\"cv-test_3utts\": 50, \"edacc-test\": 200})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### cv-test_3utts\n",
        "\n",
        "| | nan | \n",
        "| --- | --- | \n",
        "| ignorant | 0.28 |\n",
        "| lazy-informed | 0.22 |\n",
        "| whisper-small | 0.71 |\n",
        "| whisper-large | 0.53 |\n",
        "| ser-audeering-w2v | 0.99 |\n",
        "| nisqa | 3.41 |\n",
        "\n",
        "#### edacc-test\n",
        "\n",
        "| | American | Standard Indian English | Spanish | Afrian | Nigerian | African accent | Kenyan | Indian  | Spanish accent | Lithuanian | Lithuanian (eastern European) | Irish | Fluent | Israeli | Vietnamese | \n",
        "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | \n",
        "| ignorant | 0.44 |  -  | 0.17 |  -  | 0.17 |  -  |  -  |  -  |  -  |  -  |  -  | 0.5 | 0.17 |  -  | 0.28 |\n",
        "| lazy-informed | 0.44 |  -  | 0.5 |  -  | 0.5 |  -  |  -  |  -  |  -  |  -  |  -  | 0.56 | 0.17 |  -  | 0.17 |\n",
        "| whisper-small | 0.7 | 0.86 | 0.59 | 0.83 | 0.71 | 1.26 | 0.94 | 17.13 | 0.65 | 0.58 | 0.72 | 0.51 | 1.09 | 0.71 | 1.18 |\n",
        "| whisper-large | 0.47 | 0.71 | 0.44 | 0.64 | 0.6 | 0.96 | 0.71 | 17.13 | 0.51 | 0.48 | 0.58 | 0.39 | 0.87 | 0.46 | 1.01 |\n",
        "| ser-audeering-w2v | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 264.0 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 |\n",
        "| nisqa | 2.58 | 2.82 | 3.17 | 2.56 | 2.82 | 3.23 | 3.06 | 264.0 | 3.31 | 2.8 | 2.94 | 3.16 | 3.02 | 2.87 | 3.03 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#### cv-test_3utts\n",
            "\n",
            "| | male | nan | female | \n",
            "| --- | --- | --- | --- | \n",
            "| ignorant | 0.27 | 0.27 | 0.29 |\n",
            "| lazy-informed | 0.2 | 0.22 | 0.21 |\n",
            "| whisper-small | 0.75 | 0.69 | 0.52 |\n",
            "| whisper-large | 0.59 | 0.51 | 0.35 |\n",
            "| ser-audeering-w2v | 0.99 | 0.99 | 0.99 |\n",
            "| nisqa | 3.4 | 3.41 | 3.41 |\n",
            "\n",
            "#### ls-test-clean\n",
            "\n",
            "| | M | F | \n",
            "| --- | --- | --- | \n",
            "| ignorant | 0.32 | 0.34 |\n",
            "| lazy-informed | 0.32 | 0.24 |\n",
            "| whisper-small | 0.13 | 0.16 |\n",
            "| whisper-large | 0.09 | 0.1 |\n",
            "| ser-audeering-w2v | 1.0 | 1.0 |\n",
            "| nisqa | 3.02 | 3.11 |\n",
            "\n",
            "#### edacc-test\n",
            "\n",
            "| | Male | Female | \n",
            "| --- | --- | --- | \n",
            "| ignorant | 0.36 | 0.36 |\n",
            "| lazy-informed | 0.27 | 0.3 |\n",
            "| whisper-small | 0.74 | 0.74 |\n",
            "| whisper-large | 0.6 | 0.6 |\n",
            "| ser-audeering-w2v | 0.99 | 0.99 |\n",
            "| nisqa | 2.95 | 2.91 |\n",
            "\n",
            "#### ravdess\n",
            "\n",
            "| | F | M | \n",
            "| --- | --- | --- | \n",
            "| ignorant | 0.4 | 0.39 |\n",
            "| lazy-informed | 0.42 | 0.31 |\n",
            "| whisper-small | 0.76 | 0.42 |\n",
            "| whisper-large | 0.46 | 0.28 |\n",
            "| ser-audeering-w2v | 0.98 | 0.98 |\n",
            "| nisqa | 3.26 | 3.34 |\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trait = \"gender\"\n",
        "results, n_samples = get_results(trait, privacy_dirs, privacy_components, utility_dirs, utility_components)\n",
        "components = list(privacy_components) + list(utility_components)\n",
        "print_results_per_dataset(results, n_samples, components, min_samples={\"cv-test_3utts\": 20, \"edacc-test\": 20, \"ls-test-clean\": 20, \"ravdess\": 20})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### cv-test_3utts\n",
        "\n",
        "| | male | nan | female | \n",
        "| --- | --- | --- | --- | \n",
        "| ignorant | 0.27 | 0.27 | 0.29 |\n",
        "| lazy-informed | 0.2 | 0.22 | 0.21 |\n",
        "| whisper-small | 0.75 | 0.69 | 0.52 |\n",
        "| whisper-large | 0.59 | 0.51 | 0.35 |\n",
        "| ser-audeering-w2v | 0.99 | 0.99 | 0.99 |\n",
        "| nisqa | 3.4 | 3.41 | 3.41 |\n",
        "\n",
        "#### ls-test-clean\n",
        "\n",
        "| | M | F | \n",
        "| --- | --- | --- | \n",
        "| ignorant | 0.32 | 0.34 |\n",
        "| lazy-informed | 0.32 | 0.24 |\n",
        "| whisper-small | 0.13 | 0.16 |\n",
        "| whisper-large | 0.09 | 0.1 |\n",
        "| ser-audeering-w2v | 1.0 | 1.0 |\n",
        "| nisqa | 3.02 | 3.11 |\n",
        "\n",
        "#### edacc-test\n",
        "\n",
        "| | Male | Female | \n",
        "| --- | --- | --- | \n",
        "| ignorant | 0.36 | 0.36 |\n",
        "| lazy-informed | 0.27 | 0.3 |\n",
        "| whisper-small | 0.74 | 0.74 |\n",
        "| whisper-large | 0.6 | 0.6 |\n",
        "| ser-audeering-w2v | 0.99 | 0.99 |\n",
        "| nisqa | 2.95 | 2.91 |\n",
        "\n",
        "#### ravdess\n",
        "\n",
        "| | F | M | \n",
        "| --- | --- | --- | \n",
        "| ignorant | 0.4 | 0.39 |\n",
        "| lazy-informed | 0.42 | 0.31 |\n",
        "| whisper-small | 0.76 | 0.42 |\n",
        "| whisper-large | 0.46 | 0.28 |\n",
        "| ser-audeering-w2v | 0.98 | 0.98 |\n",
        "| nisqa | 3.26 | 3.34 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#### cv-test_3utts\n",
            "\n",
            "| | teens | nan | thirties | twenties | fourties | \n",
            "| --- | --- | --- | --- | --- | --- | \n",
            "| ignorant | 0.2 | 0.28 | 0.23 | 0.32 | 0.29 |\n",
            "| lazy-informed | 0.14 | 0.22 | 0.25 | 0.22 | 0.07 |\n",
            "| whisper-small | 0.95 | 0.69 | 0.65 | 0.69 | 0.6 |\n",
            "| whisper-large | 0.78 | 0.51 | 0.41 | 0.56 | 0.47 |\n",
            "| ser-audeering-w2v | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 |\n",
            "| nisqa | 3.31 | 3.41 | 3.45 | 3.33 | 3.65 |\n",
            "\n",
            "#### edacc-test\n",
            "\n",
            "| | 25 | 24 | 34 | 21 | 40 | 67 | 38 | 33 | 58 | 31 | 30 | 28 | 32 | 36 | 22 | 26 | 39 | 45 | 41 | 27 | 35 | 48 | 49 | 23 | 19 | 53 | 46 | \n",
            "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | \n",
            "| ignorant | 0.44 | 0.25 | 0.33 | 0.31 | 0.5 |  -  |  -  | 0.42 | 0.17 | 0.36 |  -  | 0.29 |  -  |  -  | 0.33 | 0.17 | 0.44 |  -  |  -  | 0.22 | 0.5 |  -  |  -  |  -  |  -  |  -  |  -  |\n",
            "| lazy-informed | 0.27 | 0.14 | 0.33 | 0.44 | 0.17 |  -  |  -  | 0.28 | 0.33 | 0.28 |  -  | 0.36 |  -  |  -  | 0.17 | 0.17 | 0.11 |  -  |  -  | 0.39 | 0.33 |  -  |  -  |  -  |  -  |  -  |  -  |\n",
            "| whisper-small | 1.03 | 0.65 | 0.82 | 0.62 | 1.13 | 0.73 | 0.58 | 0.59 | 0.45 | 0.84 | 0.51 | 0.73 | 0.59 | 0.61 | 0.76 | 0.94 | 0.6 | 0.58 | 0.65 | 1.0 | 0.74 | 0.51 | 0.71 | 0.61 | 0.7 | 0.64 | 0.77 |\n",
            "| whisper-large | 0.78 | 0.63 | 0.71 | 0.49 | 0.71 | 1.11 | 0.71 | 0.52 | 0.34 | 0.7 | 0.36 | 0.58 | 0.47 | 0.47 | 0.59 | 0.74 | 0.5 | 0.43 | 0.51 | 0.89 | 0.53 | 0.51 | 0.46 | 0.38 | 0.53 | 0.41 | 0.54 |\n",
            "| ser-audeering-w2v | 0.99 | 0.99 | 0.99 | 0.99 | 1.0 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 1.0 | 0.99 | 0.99 | 0.99 |\n",
            "| nisqa | 3.13 | 2.81 | 2.77 | 2.93 | 3.11 | 3.06 | 3.19 | 3.14 | 3.12 | 2.97 | 2.57 | 2.75 | 3.06 | 2.51 | 2.76 | 3.07 | 2.95 | 3.16 | 3.31 | 2.7 | 3.13 | 2.87 | 2.87 | 2.66 | 3.11 | 2.86 | 2.92 |\n",
            "\n",
            "#### both\n",
            "\n",
            "| | teens | nan | thirties | twenties | fourties | \n",
            "| --- | --- | --- | --- | --- | --- | \n",
            "| ignorant | 0.2 | 0.28 | 0.4 | 0.29 | 0.31 |\n",
            "| lazy-informed | 0.14 | 0.22 | 0.23 | 0.29 | 0.23 |\n",
            "| whisper-small | 0.8 | 0.69 | 0.69 | 0.8 | 0.67 |\n",
            "| whisper-large | 0.63 | 0.51 | 0.57 | 0.64 | 0.5 |\n",
            "| ser-audeering-w2v | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 |\n",
            "| nisqa | 3.19 | 3.41 | 2.96 | 2.92 | 3.05 |\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trait = \"age\"\n",
        "results, n_samples = get_results(trait, privacy_dirs, privacy_components, utility_dirs, utility_components)\n",
        "\n",
        "results[\"both\"] = dict()\n",
        "n_samples[\"both\"] = dict()\n",
        "for age_group, components in results[\"cv-test_3utts\"].items():\n",
        "    results[\"both\"][age_group] = dict()\n",
        "    for component, values in components.items():\n",
        "        results[\"both\"][age_group][component] = [sum(values) / len(values)] * n_samples[\"cv-test_3utts\"][age_group]\n",
        "        n_samples[\"both\"][age_group] = n_samples[\"cv-test_3utts\"][age_group]\n",
        "\n",
        "for age, components in results[\"edacc-test\"].items():\n",
        "    if age.startswith(\"1\"):\n",
        "        age_group = \"teens\"\n",
        "    elif age.startswith(\"2\"):\n",
        "        age_group = \"twenties\"\n",
        "    elif age.startswith(\"3\"):\n",
        "        age_group = \"thirties\"\n",
        "    else:\n",
        "        age_group = \"fourties\"\n",
        "    for component, values in components.items():\n",
        "        results[\"both\"][age_group][component] += [sum(values) / len(values)] * n_samples[\"edacc-test\"][age]\n",
        "        n_samples[\"both\"][age_group] = n_samples[\"edacc-test\"][age]\n",
        "\n",
        "for age_group, components in results[\"both\"].items():\n",
        "    for component, values in components.items():\n",
        "        results[\"both\"][age_group][component] = sum(values) / len(values)\n",
        "\n",
        "\n",
        "components = list(privacy_components) + list(utility_components)\n",
        "print_results_per_dataset(results, n_samples, components, min_samples={\"cv-test_3utts\": 20, \"edacc-test\": 20, \"both\": 20})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### cv-test_3utts\n",
        "\n",
        "| | teens | nan | thirties | twenties | fourties | \n",
        "| --- | --- | --- | --- | --- | --- | \n",
        "| ignorant | 0.2 | 0.28 | 0.23 | 0.32 | 0.29 |\n",
        "| lazy-informed | 0.14 | 0.22 | 0.25 | 0.22 | 0.07 |\n",
        "| whisper-small | 0.95 | 0.69 | 0.65 | 0.69 | 0.6 |\n",
        "| whisper-large | 0.78 | 0.51 | 0.41 | 0.56 | 0.47 |\n",
        "| ser-audeering-w2v | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 |\n",
        "| nisqa | 3.31 | 3.41 | 3.45 | 3.33 | 3.65 |\n",
        "\n",
        "#### edacc-test\n",
        "\n",
        "| | 25 | 24 | 34 | 21 | 40 | 67 | 38 | 33 | 58 | 31 | 30 | 28 | 32 | 36 | 22 | 26 | 39 | 45 | 41 | 27 | 35 | 48 | 49 | 23 | 19 | 53 | 46 | \n",
        "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | \n",
        "| ignorant | 0.44 | 0.25 | 0.33 | 0.31 | 0.5 |  -  |  -  | 0.42 | 0.17 | 0.36 |  -  | 0.29 |  -  |  -  | 0.33 | 0.17 | 0.44 |  -  |  -  | 0.22 | 0.5 |  -  |  -  |  -  |  -  |  -  |  -  |\n",
        "| lazy-informed | 0.27 | 0.14 | 0.33 | 0.44 | 0.17 |  -  |  -  | 0.28 | 0.33 | 0.28 |  -  | 0.36 |  -  |  -  | 0.17 | 0.17 | 0.11 |  -  |  -  | 0.39 | 0.33 |  -  |  -  |  -  |  -  |  -  |  -  |\n",
        "| whisper-small | 1.03 | 0.65 | 0.82 | 0.62 | 1.13 | 0.73 | 0.58 | 0.59 | 0.45 | 0.84 | 0.51 | 0.73 | 0.59 | 0.61 | 0.76 | 0.94 | 0.6 | 0.58 | 0.65 | 1.0 | 0.74 | 0.51 | 0.71 | 0.61 | 0.7 | 0.64 | 0.77 |\n",
        "| whisper-large | 0.78 | 0.63 | 0.71 | 0.49 | 0.71 | 1.11 | 0.71 | 0.52 | 0.34 | 0.7 | 0.36 | 0.58 | 0.47 | 0.47 | 0.59 | 0.74 | 0.5 | 0.43 | 0.51 | 0.89 | 0.53 | 0.51 | 0.46 | 0.38 | 0.53 | 0.41 | 0.54 |\n",
        "| ser-audeering-w2v | 0.99 | 0.99 | 0.99 | 0.99 | 1.0 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 1.0 | 0.99 | 0.99 | 0.99 |\n",
        "| nisqa | 3.13 | 2.81 | 2.77 | 2.93 | 3.11 | 3.06 | 3.19 | 3.14 | 3.12 | 2.97 | 2.57 | 2.75 | 3.06 | 2.51 | 2.76 | 3.07 | 2.95 | 3.16 | 3.31 | 2.7 | 3.13 | 2.87 | 2.87 | 2.66 | 3.11 | 2.86 | 2.92 |\n",
        "\n",
        "#### both\n",
        "\n",
        "| | teens | nan | thirties | twenties | fourties | \n",
        "| --- | --- | --- | --- | --- | --- | \n",
        "| ignorant | 0.2 | 0.28 | 0.4 | 0.29 | 0.31 |\n",
        "| lazy-informed | 0.14 | 0.22 | 0.23 | 0.29 | 0.23 |\n",
        "| whisper-small | 0.8 | 0.69 | 0.69 | 0.8 | 0.67 |\n",
        "| whisper-large | 0.63 | 0.51 | 0.57 | 0.64 | 0.5 |\n",
        "| ser-audeering-w2v | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 |\n",
        "| nisqa | 3.19 | 3.41 | 2.96 | 2.92 | 3.05 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#### edacc-test\n",
            "\n",
            "| | White | South Asian | Asian | Black | Mixed | Latin American | \n",
            "| --- | --- | --- | --- | --- | --- | --- | \n",
            "| ignorant | 0.39 | 0.38 | 0.38 | 0.39 |  -  |  -  |\n",
            "| lazy-informed | 0.3 | 0.31 | 0.2 | 0.29 |  -  |  -  |\n",
            "| whisper-small | 0.61 | 0.78 | 0.73 | 0.88 | 0.7 | 0.51 |\n",
            "| whisper-large | 0.51 | 0.63 | 0.58 | 0.7 | 0.44 | 0.36 |\n",
            "| ser-audeering-w2v | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 |\n",
            "| nisqa | 3.02 | 2.84 | 2.92 | 2.89 | 2.73 | 2.57 |\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trait = \"ethnicity\"\n",
        "results, n_samples = get_results(trait, privacy_dirs, privacy_components, utility_dirs, utility_components)\n",
        "components = list(privacy_components) + list(utility_components)\n",
        "print_results_per_dataset(results, n_samples, components, min_samples={\"cv-test_3utts\": 20, \"edacc-test\": 20, \"ls-test-clean\": 20, \"ravdess\": 20})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### edacc-test\n",
        "\n",
        "| | White | South Asian | Asian | Black | Mixed | Latin American | \n",
        "| --- | --- | --- | --- | --- | --- | --- | \n",
        "| ignorant | 0.39 | 0.38 | 0.38 | 0.39 |  -  |  -  |\n",
        "| lazy-informed | 0.3 | 0.31 | 0.2 | 0.29 |  -  |  -  |\n",
        "| whisper-small | 0.61 | 0.78 | 0.73 | 0.88 | 0.7 | 0.51 |\n",
        "| whisper-large | 0.51 | 0.63 | 0.58 | 0.7 | 0.44 | 0.36 |\n",
        "| ser-audeering-w2v | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 | 0.99 |\n",
        "| nisqa | 3.02 | 2.84 | 2.92 | 2.89 | 2.73 | 2.57 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#### ravdess\n",
            "\n",
            "| | angry | fearful | disgust | sad | surprised | happy | calm | neutral | \n",
            "| --- | --- | --- | --- | --- | --- | --- | --- | --- | \n",
            "| ignorant | 0.36 | 0.53 | 0.33 | 0.67 | 0.33 | 0.22 | 0.31 | 0.5 |\n",
            "| lazy-informed | 0.36 | 0.25 | 0.0 | 0.33 | 0.17 | 0.42 | 0.42 | 0.33 |\n",
            "| whisper-small | 0.58 | 1.14 | 0.48 | 0.58 | 0.59 | 0.65 | 0.26 | 0.26 |\n",
            "| whisper-large | 0.43 | 0.55 | 0.28 | 0.34 | 0.46 | 0.32 | 0.16 | 0.51 |\n",
            "| ser-audeering-w2v | 0.98 | 0.98 | 0.98 | 0.98 | 0.98 | 0.98 | 0.99 | 0.99 |\n",
            "| nisqa | 3.08 | 3.19 | 3.4 | 3.35 | 3.2 | 3.2 | 3.65 | 3.42 |\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trait = \"utt_emotion\"\n",
        "results, n_samples = get_results(trait, privacy_dirs, privacy_components, utility_dirs, utility_components)\n",
        "components = list(privacy_components) + list(utility_components)\n",
        "print_results_per_dataset(results, n_samples, components, min_samples={\"cv-test_3utts\": 20, \"edacc-test\": 20, \"ls-test-clean\": 20, \"ravdess\": 20})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ravdess\n",
        "\n",
        "| | angry | fearful | disgust | sad | surprised | happy | calm | neutral | \n",
        "| --- | --- | --- | --- | --- | --- | --- | --- | --- | \n",
        "| ignorant | 0.36 | 0.53 | 0.33 | 0.67 | 0.33 | 0.22 | 0.31 | 0.5 |\n",
        "| lazy-informed | 0.36 | 0.25 | 0.0 | 0.33 | 0.17 | 0.42 | 0.42 | 0.33 |\n",
        "| whisper-small | 0.58 | 1.14 | 0.48 | 0.58 | 0.59 | 0.65 | 0.26 | 0.26 |\n",
        "| whisper-large | 0.43 | 0.55 | 0.28 | 0.34 | 0.46 | 0.32 | 0.16 | 0.51 |\n",
        "| ser-audeering-w2v | 0.98 | 0.98 | 0.98 | 0.98 | 0.98 | 0.98 | 0.99 | 0.99 |\n",
        "| nisqa | 3.08 | 3.19 | 3.4 | 3.35 | 3.2 | 3.2 | 3.65 | 3.42 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "0303e71b09c4ef6371fdb6bee0728d2bfa84e4cc09a309a2d2b1e6ca43341d44"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
